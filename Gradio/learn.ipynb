{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1ce2564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import requests\n",
    "from typing import List\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "657c40a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API KEY IS READY\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API\")\n",
    "if api_key and api_key[:8] == \"sk-proj-\":\n",
    "    print(\"API KEY IS READY\")\n",
    "else:\n",
    "    print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "864447ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(api_key=api_key)\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bee8914",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant please answer to the user's query precisely.\n",
    "If you don't know the answer just say that I am not familiar with it.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25a8db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\"content\":system_prompt},\n",
    "        {\"role\":\"user\",\"content\":prompt}\n",
    "    ]\n",
    "    completion = openai.chat.completions.create(\n",
    "        model = MODEL,\n",
    "        messages=messages,\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c173c890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Today's date is October 24, 2023.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_gpt(\"What is todays date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c547dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UP_UP(text):\n",
    "    return text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2aa73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MASTERING_LLMs\\llmEnv\\lib\\site-packages\\gradio\\interface.py:419: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(fn=UP_UP,inputs=\"textbox\",outputs=\"textbox\",allow_flagging=\"never\").launch()\n",
    "# gr.Interface(fn=UP_UP,inputs=\"textbox\",outputs=\"textbox\",allow_flagging=\"never\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef28072a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MASTERING_LLMs\\llmEnv\\lib\\site-packages\\gradio\\interface.py:419: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    inputs=gr.Textbox(label=\"Your Message\",lines=6),\n",
    "    outputs=gr.Textbox(label=\"Response\",lines=8),\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b6a382b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MASTERING_LLMs\\llmEnv\\lib\\site-packages\\gradio\\interface.py:419: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=UP_UP,\n",
    "    inputs=gr.Textbox(label=\"Your Message\",lines=6),\n",
    "    outputs=gr.Markdown(label=\"Response\"),\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "526773ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_output(prompt):\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\"content\":system_prompt},\n",
    "        {\"role\":\"user\",\"content\":prompt}\n",
    "    ]\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07fb91e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MASTERING_LLMs\\llmEnv\\lib\\site-packages\\gradio\\interface.py:419: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_output,\n",
    "    inputs=gr.Textbox(label=\"Your Message:\"),\n",
    "    outputs=gr.Markdown(label=\"Response\"),\n",
    "    allow_flagging=\"never\",\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1051b11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    def __init__(self,url):\n",
    "        self.url = url\n",
    "        response = requests.get(self.url)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body,\"html.parser\")\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\",\"style\",\"img\",\"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator='\\n',strip=True)\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title: {self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e4a8210",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assitant that analyzes the contents of a company landing page \\\n",
    "and create a short brochure about the company for customers, investors and recruiters. Respond in Markdown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6edaa3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(title,url):\n",
    "    prompt = f\"Please provide a company brochure for {title}, here is their landing page:\\n{Website(url).get_contents()}\"\n",
    "    result = stream_output(prompt=prompt)\n",
    "    for chunk in result:\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834edcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please provide a company brochure for Anthropic, here is their landing page:\\nWebpage Title: Home \\\\ Anthropic\\nWebpage Contents:\\nSkip to main content\\nSkip to footer\\nClaude\\nChat with Claude\\nOverview\\nTeam plan\\nEnterprise plan\\nEducation plan\\nExplore pricing\\nDownload apps\\nClaude log in\\nNews\\nClaude‚Äôs character\\nAPI\\nBuild with Claude\\nAPI\\xa0overview\\nDeveloper docs\\nExplore pricing\\nConsole log in\\nNews\\nLearn how to build with Claude\\nSolutions\\nCollaborate with Claude\\nAI\\xa0agents\\nCoding\\nCustomer support\\nCase studies\\nHear from our customers\\nResearch\\nResearch\\nOverview\\nEconomic Index\\nClaude model family\\nClaude Opus 4\\nClaude Sonnet 4\\nClaude Haiku 3.5\\nResearch\\nClaude‚Äôs extended thinking\\nCommitments\\nInitiatives\\nTransparency\\nResponsible scaling policy\\nTrust center\\nSecurity and compliance\\nAnnouncement\\nISO\\xa042001 certification\\nLearn\\nLearning resources\\nCustomer stories\\nEngineering at Anthropic\\nAnthropic Academy\\nCompany\\nAbout\\nCareers\\nEvents\\nEngineering\\nBuilding effective agents\\nNews\\nEN\\nThis is some text inside of a div block.\\nTry Claude\\nTry Claude\\nTry Claude\\nDownload App\\nDownload App\\nDownload App\\nClaude\\nChat with Claude\\nOverview\\nTeam plan\\nEnterprise plan\\nEducation plan\\nExplore pricing\\nDownload apps\\nClaude log in\\nNews\\nClaude‚Äôs character\\nAPI\\nBuild with Claude\\nAPI\\xa0overview\\nDeveloper docs\\nExplore pricing\\nConsole log in\\nNews\\nLearn how to build with Claude\\nSolutions\\nCollaborate with Claude\\nAI\\xa0agents\\nCoding\\nCustomer support\\nCase studies\\nHear from our customers\\nResearch\\nResearch\\nOverview\\nEconomic Index\\nClaude model family\\nClaude Opus 4\\nClaude Sonnet 4\\nClaude Haiku 3.5\\nResearch\\nClaude‚Äôs extended thinking\\nCommitments\\nInitiatives\\nTransparency\\nResponsible scaling policy\\nTrust center\\nSecurity and compliance\\nAnnouncement\\nISO\\xa042001 certification\\nLearn\\nLearning resources\\nCustomer stories\\nEngineering at Anthropic\\nAnthropic Academy\\nCompany\\nAbout\\nCareers\\nEvents\\nEngineering\\nBuilding effective agents\\nNews\\nEN\\nThis is some text inside of a div block.\\nTry Claude\\nTry Claude\\nTry Claude\\nDownload App\\nDownload App\\nDownload App\\nAI\\nresearch\\nand\\nproducts\\nthat put safety at the frontier\\nClaude.ai\\nMeet Claude Opus 4\\nClaude Opus 4, our most intelligent AI model, is now available.\\nTalk to Claude\\nTalk to Claude\\nTalk to Claude\\nAPI\\nBuild with Claude\\nCreate AI-powered applications and custom experiences using Claude.\\nLearn more\\nLearn more\\nLearn more\\nClaude Opus 4 and Sonnet 4\\nOur most powerful models yet, pushing the frontier for coding and AI agents‚Äîand enabling Claude to handle hours of work across Claude and Claude Code.\\nRead announcement\\nRead announcement\\nRead announcement\\nModel details\\nOpus 4\\nLearn more Claude Opus 4\\nLearn more Claude Opus 4\\nModel details\\nSonnet 4\\nLearn more about Sonnet 4\\nLearn more about Sonnet 4\\n‚Äú\\nIf knowledge is power and we‚Äôre building machines that have more knowledge than us, what will happen between us and the machines?\\nDeep Ganguli\\nResearch Lead, Societal Impacts\\nAt Anthropic, we build AI to serve humanity‚Äôs long-term well-being.\\n\\u200d\\nWhile no one can foresee every outcome AI will have on society, we do know that designing powerful technologies requires both bold steps forward and intentional pauses to consider the effects.\\nThat‚Äôs why we focus on building tools with human benefit at their foundation, like Claude. Through our daily research, policy work, and product design, we aim to show what responsible AI development looks like in practice.\\nCore Views on AI Safety\\nLearn more about our views on AI Safety\\nLearn more about our views on AI Safety\\nAnthropic‚Äôs Responsible Scaling Policy\\nLearn more about our Responsible Scaling Policy\\nLearn more about our Responsible Scaling Policy\\nAnthropic Academy: Learn to build with Claude\\nAccess Anthropic Academy\\nAccess Anthropic Academy\\nFeatured\\nTracing the thoughts of a large language model\\nInterpretability\\nMar 27, 2025\\nAnthropic Economic Index\\nSocietal impacts\\nMar 27, 2025\\nClaude 3.7 Sonnet and Claude Code\\nProduct\\nFeb 24, 2025\\nClaude‚Äôs extended thinking\\nProduct\\nFeb 24, 2025\\nAlignment faking in large language models\\nAlignment science\\nDec 18, 2024\\nIntroducing the Model Context Protocol\\nProduct\\nNov 25, 2024\\nWant to help us build the future of safe AI?\\nSee open roles\\nSee open roles\\nSee open roles\\nSpeak with sales\\nSpeak with sales\\nSpeak with sales\\nFooter\\nProduct\\nClaude overview\\nClaude Code\\nClaude team plan\\nClaude enterprise plan\\nClaude education plan\\nDownload Claude apps\\nClaude.ai pricing plans\\nClaude.ai login\\nAPI\\xa0Platform\\nAPI\\xa0overview\\nDeveloper docs\\nClaude in Amazon Bedrock\\nClaude on Google Cloud‚Äôs Vertex AI\\nPricing\\nConsole login\\nResearch\\nResearch overview\\nEconomic Index\\nClaude models\\nClaude Opus 4\\nClaude Sonnet 4\\nClaude Haiku 3.5\\nCommitments\\nTransparency\\nResponsible scaling policy\\nSecurity and compliance\\nSolutions\\nAI\\xa0agents\\nCoding\\nCustomer support\\nLearn\\nAnthropic Academy\\nCustomer stories\\nEngineering at Anthropic\\nMCP\\xa0Integrations\\nExplore\\nAbout us\\nBecome a partner\\nCareers\\nEvents\\nNews\\nStartups program\\nHelp and security\\nStatus\\nAvailability\\nSupport center\\nTerms and policies\\nPrivacy choices\\nCookie Settings\\nWe use cookies to deliver and improve our services, analyze site usage, and if you agree, to customize or personalize your experience and market our services to you. You can read our Cookie Policy\\nhere\\n.\\nCustomize\\ncookie settings\\nReject\\nall cookies\\nAccept\\nall cookies\\nNecessary\\nEnables security and basic functionality.\\nRequired\\nAnalytics\\nEnables tracking of site performance.\\nOff\\nMarketing\\nEnables ads personalization and tracking.\\nOff\\nSave preferences\\nPrivacy policy\\nResponsible disclosure policy\\nTerms of service - consumer\\nTerms of service - commercial\\nUsage policy\\n¬©\\n2024\\nAnthropic PBC\\n\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stream_brochure(\"Anthropic\",\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1be9d434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MASTERING_LLMs\\llmEnv\\lib\\site-packages\\gradio\\interface.py:419: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_brochure,\n",
    "    inputs= [gr.Textbox(label=\"Company name: \"),\n",
    "             gr.Textbox(label=\"Landing Page URL: \"),\n",
    "             ],\n",
    "    outputs=gr.Markdown(label=\"Brochure:\"),\n",
    "    allow_flagging=\"never\",\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc07a045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Webpage Title: Hugging Face ‚Äì The AI community building the future.\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nnanonets/Nanonets-OCR-s\\nUpdated\\n5 days ago\\n‚Ä¢\\n177k\\n‚Ä¢\\n1.17k\\ngoogle/magenta-realtime\\nUpdated\\n3 days ago\\n‚Ä¢\\n316\\nmistralai/Mistral-Small-3.2-24B-Instruct-2506\\nUpdated\\n4 days ago\\n‚Ä¢\\n5.37k\\n‚Ä¢\\n241\\nMiniMaxAI/MiniMax-M1-80k\\nUpdated\\n1 day ago\\n‚Ä¢\\n10.4k\\n‚Ä¢\\n580\\nOmniGen2/OmniGen2\\nUpdated\\n2 days ago\\n‚Ä¢\\n1.15k\\n‚Ä¢\\n160\\nBrowse 1M+ models\\nSpaces\\nRunning\\n828\\n828\\nSparc3D\\nüèÉ\\nNext-Gen High-Resolution 3D Model Generation\\nRunning\\n8.62k\\n8.62k\\nDeepSite v2\\nüê≥\\nGenerate any application with DeepSeek\\nRunning\\non\\nZero\\n467\\n467\\nHunyuan3D-2.1\\nüëª\\nImage-to-3D Generation\\nRunning\\non\\nZero\\n210\\n210\\nOmniGen2\\nüëÄ\\nOmniGen2: Unified Image Understanding and Generation.\\nRunning\\non\\nZero\\nMCP\\n151\\n151\\nSelf Forcing Wan 2.1\\nüé•\\nReal-time video generation\\nBrowse 400k+ applications\\nDatasets\\nEssentialAI/essential-web-v1.0\\nUpdated\\n3 days ago\\n‚Ä¢\\n75.5k\\n‚Ä¢\\n150\\nfka/awesome-chatgpt-prompts\\nUpdated\\nJan 6\\n‚Ä¢\\n22.9k\\n‚Ä¢\\n8.03k\\ninstitutional/institutional-books-1.0\\nUpdated\\n10 days ago\\n‚Ä¢\\n38.2k\\n‚Ä¢\\n185\\nnvidia/AceReason-1.1-SFT\\nUpdated\\n7 days ago\\n‚Ä¢\\n2.95k\\n‚Ä¢\\n42\\nBAAI/CCI4.0-M2-CoT-v1\\nUpdated\\n16 days ago\\n‚Ä¢\\n5.45k\\n‚Ä¢\\n39\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nCompute\\nDeploy on optimized\\nInference Endpoints\\nor update your\\nSpaces applications\\nto a GPU in a few clicks.\\nView pricing\\nStarting at $0.60/hour for GPU\\nEnterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at $20/user/month\\nSingle Sign-On\\nRegions\\nPriority Support\\nAudit Logs\\nResource Groups\\nPrivate Datasets Viewer\\nMore than 50,000 organizations are using Hugging Face\\nAi2\\nEnterprise\\nnon-profit\\n‚Ä¢\\n767 models\\n‚Ä¢\\n3.49k followers\\nAI at Meta\\nEnterprise\\ncompany\\n‚Ä¢\\n2.17k models\\n‚Ä¢\\n6.59k followers\\nAmazon\\ncompany\\n‚Ä¢\\n20 models\\n‚Ä¢\\n3.26k followers\\nGoogle\\ncompany\\n‚Ä¢\\n1k models\\n‚Ä¢\\n17.4k followers\\nIntel\\ncompany\\n‚Ä¢\\n204 models\\n‚Ä¢\\n2.67k followers\\nMicrosoft\\ncompany\\n‚Ä¢\\n395 models\\n‚Ä¢\\n13.2k followers\\nGrammarly\\nTeam\\ncompany\\n‚Ä¢\\n10 models\\n‚Ä¢\\n165 followers\\nWriter\\nEnterprise\\ncompany\\n‚Ä¢\\n21 models\\n‚Ä¢\\n299 followers\\nOur Open Source\\nWe are building the foundation of ML tooling with the community.\\nTransformers\\n146,067\\nState-of-the-art ML for PyTorch, TensorFlow, JAX\\nDiffusers\\n29,483\\nState-of-the-art Diffusion models in PyTorch\\nSafetensors\\n3,326\\nSafe way to store/distribute neural network weights\\nHub Python Library\\n2,713\\nPython client to interact with the Hugging Face Hub\\nTokenizers\\n9,836\\nFast tokenizers optimized for research & production\\nTRL\\n14,339\\nTrain transformers LMs with reinforcement learning\\nTransformers.js\\n13,894\\nState-of-the-art ML running directly in your browser\\nsmolagents\\n20,558\\nSmol library to build great agents in Python\\nPEFT\\n18,849\\nParameter-efficient finetuning for large language models\\nDatasets\\n20,305\\nAccess & share datasets for any ML tasks\\nText Generation Inference\\n10,254\\nServe language models with TGI optimized toolkit\\nAccelerate\\n8,871\\nTrain PyTorch models with multi-GPU, TPU, mixed precision\\nSystem theme\\nWebsite\\nModels\\nDatasets\\nSpaces\\nChangelog\\nInference Endpoints\\nHuggingChat\\nCompany\\nAbout\\nBrand assets\\nTerms of service\\nPrivacy\\nJobs\\nPress\\nResources\\nLearn\\nDocumentation\\nBlog\\nForum\\nService Status\\nSocial\\nGitHub\\nTwitter\\nLinkedIn\\nDiscord\\n\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378864e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
